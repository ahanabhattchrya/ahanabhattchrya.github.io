<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/86fdec36ddd9097e-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/fee37c95396f4079.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/99898c7091afeebc.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-b6b967ef7d8f2d7c.js"/><script src="/_next/static/chunks/fd9d1056-2821b0f0cabcd8bd.js" async=""></script><script src="/_next/static/chunks/23-323bb3d0b3ccf4a6.js" async=""></script><script src="/_next/static/chunks/main-app-5bf0fd94b7a406ed.js" async=""></script><script src="/_next/static/chunks/42-65ca5286147e5059.js" async=""></script><script src="/_next/static/chunks/app/layout-f255be880dc7323f.js" async=""></script><title>Ahana Bhattacharya</title><meta name="description" content="Generated by create next app"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="32x32"/><meta name="next-size-adjust"/><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_2c91d1"><header class="navbar_header__K34ev"><div class="navbar_wrap__3s_8l"><div class="navbar_nameBlock__PNRHI"><a href="/" class="navbar_header_title__GUzQW">Ahana B.</a><a class="navbar_pronouns__Fb1M7" href="https://cdn.ostem.org/publicfiles/PronounsWhyTheyMatter.pdf">she/her</a></div><div class="navbar_menu__DWXRf"><ul class="navbar_menu_list__LsKtc"><li class="navbar_menu_list_item__Vgnio"><a class="navbar_menu_list_item_link__3a39J navbar_active__oDF96" href="/research">Research</a><a class="navbar_menu_list_item_link__3a39J navbar_active__oDF96" href="/research">CV</a><a class="navbar_menu_list_item_link__3a39J " href="/travel">Travel</a><a class="navbar_menu_list_item_link__3a39J " href="/contact">Coffee?</a></li></ul></div></div></header><main class="research_main__jvZQ8"><div class="research_content__4TgIF"><div class="research_interest__NunHn"><p class="research_interestTitle__weqoA">Area(s) of Interest</p><hr/><p>My interests broadly lie in <b>algorithmic fairness</b> — particularly in the domains of hiring, education, healthcare, and criminal justice — as well as <b>AI governance</b> and <b>tech policy</b>. I&#x27;d like to investigate the use of machine learning algorithms in social systems that have been historically discriminatory and biased through theoretical models and causal inference.</p><p>In the near future, I plan on applying to PhD programs in Computer Science that focus on the above areas, and hope to integrate literature in <b>Psychology</b>, <b>Sociology</b>, <b>Economics</b>, <b>Queer Theory</b>, and <b>Critical Race Theory</b> into my work.</p></div><div class="research_papers__Nf7_a"><div class="research_ongoing__OLVao"><h2 class="research_ongoingTitle__l32F9">Ongoing Paper(s)</h2><div class="research_projectDescription__Zdc7Y"><p><b>Project Description</b>: Machine learning (ML) models are increasingly being used in a wide range of application domains (e.g., loan applications, healthcare, hiring, criminal justice, etc.). There is mounting concern that the complexity and opacity of ML models perpetuates systemic biases and discrimination reflected in training data. The naive way to determine whether a model is biased is to compare its predictions on subpopulations of the test data. Imagine implementing this process on an expensive multi-layer feed-forward neural network -- only to find that the model is biased and should not be used for the task. It is of interest to determine whether an ML model is fair even before deploying it in practical real-time applications.</p></div><div><p><b>RQ</b>: Can we measure the goodness of data for fairness of downstream ML tasks?</p></div></div><div class="research_review__F1h4K"><h2 class="research_reviewTitle__Nvwft">Under Review</h2><h3> The &#x27;Who,&#x27; &#x27;How,&#x27; and &#x27;When,&#x27; of Elite Political Discourse on Twitter/X Before and After the Murder of George Floyd.</h3><div class="research_coauthors__PUOnm"> Alyssa Smith, Ahana Bhattacharya, Holliday Sims, Kenneth Joseph</div><div class="research_abstract__lZrrO"><p><b>Abstract</b>: Most U.S. Twitter/X users are not exposed to, and do not engage with, much political talk on average, yet strong evidence indicates that many Americans are aware of political movements and are often, in fact, tired of hearing about politics on social media. Additionally, much of the work on online political discussion in the U.S. context focuses on traditional political elites and speech that discusses American electoral politics. However, there exist other influential accounts on social media besides political elites, and there are other topics of political discussion besides American electoral politics; there is still work to be done to understand who mobilizes with a political movement, when they do so, and to what extent they engage. The present work targets these questions, aided by a unique combination of mixed methods analyses, a dataset of the following relationships in 2020 of 1.4 million American voters linked to Twitter/X accounts, and an archive of the Twitter/X Decahose, a 10% random streaming sample of all tweets. Using a recently proposed method for clustering frequently followed accounts, we create a taxonomy of account clusters, ranging from golf turf enthusiasts to liberal activists. We then examine the mobilization of these clusters after George Floyd&#x27;s murder, measuring levels of discussion of U.S. electoral politics and of the Black Lives Matter movement. Our findings show that seemingly apolitical elites actually mobilized more after Floyd&#x27;s death than political elites did. We also emphasize the importance of temporality in measuring mobilization. While Twitter/X users may not see much political talk on average, significant spikes in political and BLM-related discourse occurred after Floyd&#x27;s death, and these resulted in persistent changes in levels of BLM-related discussion. Our findings problematize current conceptions of online political behavior and suggest new ways to investigate civic engagement on social media.</p></div><h3> Justice in Child Welfare Policy: Towards the Development of a Contextual Ethics Framework for Deployment of AI in Human Service Systems.</h3><div class="research_coauthors__PUOnm">Maria Rodriguez, Seventy Hall, Kenneth Joseph, Ahana Bhattacharya, Benson Cai, Hannah Wilcox, and Connor Wurst</div><div class="research_abstract__lZrrO"><p><b>Abstract</b>: Scholars investigating AI in high stakes settings have proposed ML solutions ranging from reformist to progressive, attempting to adjudicate between justice as equity and justice as fairness. Progressive work asks the system to reorder its prioritization of the values that define justice (equity), while reformist work builds tools that work within the existing justice value structure (fairness). The present work asks: what are the justice values (implied or enacted) by state-level child welfare administrative policy in the United States? We conduct a mixed-methods analysis of child welfare policy in the United States and find a range of implied justice values within administrative rules, from established concepts like fairness and equity to more nuanced foci on bodies as property. Our work contributes to a deeper understanding of the interplay between AI and policy, highlighting the importance of enacted values in shaping how we design AI tools in high stakes decision settings.</p></div></div></div></div></main><footer class="footer_footer__KDdEv"><div class="footer_footerBlock__PXFG6"><div class="footer_socials__4wRIl"><a href="mailto:ahanabhattchrya@gmail.com"><svg class="footer_gmail__f_p2B" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M64 112c-8.8 0-16 7.2-16 16l0 22.1L220.5 291.7c20.7 17 50.4 17 71.1 0L464 150.1l0-22.1c0-8.8-7.2-16-16-16L64 112zM48 212.2L48 384c0 8.8 7.2 16 16 16l384 0c8.8 0 16-7.2 16-16l0-171.8L322 328.8c-38.4 31.5-93.7 31.5-132 0L48 212.2zM0 128C0 92.7 28.7 64 64 64l384 0c35.3 0 64 28.7 64 64l0 256c0 35.3-28.7 64-64 64L64 448c-35.3 0-64-28.7-64-64L0 128z"></path></svg></a><a href="https://www.linkedin.com/in/ah4na/"><svg class="footer_linkedin__U8WKc" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></div><div class="footer_footerText__hMIQC"><p>© Copyright 2024 Ahana Bhattacharya</p></div></div></footer><script src="/_next/static/chunks/webpack-b6b967ef7d8f2d7c.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/media/86fdec36ddd9097e-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/css/fee37c95396f4079.css\",\"style\"]\n3:HL[\"/_next/static/css/99898c7091afeebc.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"4:I[5751,[],\"\"]\n7:I[9275,[],\"\"]\n8:I[1343,[],\"\"]\n9:I[43,[\"42\",\"static/chunks/42-65ca5286147e5059.js\",\"185\",\"static/chunks/app/layout-f255be880dc7323f.js\"],\"default\"]\nb:I[6130,[],\"\"]\n6:T7b6,: Most U.S. Twitter/X users are not exposed to, and do not engage with, much political talk on average, yet strong evidence indicates that many Americans are aware of political movements and are often, in fact, tired of hearing about politics on social media. Additionally, much of the work on online political discussion in the U.S. context focuses on traditional political elites and speech that discusses American electoral politics. However, there exist other influential accounts on social media besides political elites, and there are other topics of political discussion besides American electoral politics; there is still work to be done to understand who mobilizes with a political movement, when they do so, and to what extent they engage. The present work targets these questions, aided by a unique combination of mixed methods analyses, a dataset of the following relationships in 2020 of 1.4 million American voters linked to Twitter/X accounts, and an archive of the Twitter/X Decahose, a 10% random streaming sample of all tweets. Using a recently proposed method for clustering frequently followed accounts, we create a taxonomy of account clusters, ranging from golf turf enthusiasts to liberal activists. We then examine the mobilization of these clusters after George Floyd's murder, measuring levels of discussion of U.S. electoral politics and of the Black Lives Matter movement. Our findings show that seemingly apolitical elites actually mobilized more after Floyd's death than political elites did. We also emphasize the importance of temporality in measuring mobilization. While Twitter/X users may not see much political talk on average, significant spikes in political and BLM-related discourse occurred after Floyd's death, and these resulted in persistent changes in levels of BLM-related discussion. Our findings problematize curr"])</script><script>self.__next_f.push([1,"ent conceptions of online political behavior and suggest new ways to investigate civic engagement on social media.c:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/fee37c95396f4079.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L4\",null,{\"buildId\":\"V6QAlonYB1Vk-2AwQ77te\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/research\",\"initialTree\":[\"\",{\"children\":[\"research\",{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"research\",{\"children\":[\"__PAGE__\",{},[[\"$L5\",[\"$\",\"main\",null,{\"className\":\"research_main__jvZQ8\",\"children\":[\"$\",\"div\",null,{\"className\":\"research_content__4TgIF\",\"children\":[[\"$\",\"div\",null,{\"className\":\"research_interest__NunHn\",\"children\":[[\"$\",\"p\",null,{\"className\":\"research_interestTitle__weqoA\",\"children\":\"Area(s) of Interest\"}],[\"$\",\"hr\",null,{}],[\"$\",\"p\",null,{\"children\":[\"My interests broadly lie in \",[\"$\",\"b\",null,{\"children\":\"algorithmic fairness\"}],\" — particularly in the domains of hiring, education, healthcare, and criminal justice — as well as \",[\"$\",\"b\",null,{\"children\":\"AI governance\"}],\" and \",[\"$\",\"b\",null,{\"children\":\"tech policy\"}],\". I'd like to investigate the use of machine learning algorithms in social systems that have been historically discriminatory and biased through theoretical models and causal inference.\"]}],[\"$\",\"p\",null,{\"children\":[\"In the near future, I plan on applying to PhD programs in Computer Science that focus on the above areas, and hope to integrate literature in \",[\"$\",\"b\",null,{\"children\":\"Psychology\"}],\", \",[\"$\",\"b\",null,{\"children\":\"Sociology\"}],\", \",[\"$\",\"b\",null,{\"children\":\"Economics\"}],\", \",[\"$\",\"b\",null,{\"children\":\"Queer Theory\"}],\", and \",[\"$\",\"b\",null,{\"children\":\"Critical Race Theory\"}],\" into my work.\"]}]]}],[\"$\",\"div\",null,{\"className\":\"research_papers__Nf7_a\",\"children\":[[\"$\",\"div\",null,{\"className\":\"research_ongoing__OLVao\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"research_ongoingTitle__l32F9\",\"children\":\"Ongoing Paper(s)\"}],[\"$\",\"div\",null,{\"className\":\"research_projectDescription__Zdc7Y\",\"children\":[\"$\",\"p\",null,{\"children\":[[\"$\",\"b\",null,{\"children\":\"Project Description\"}],\": Machine learning (ML) models are increasingly being used in a wide range of application domains (e.g., loan applications, healthcare, hiring, criminal justice, etc.). There is mounting concern that the complexity and opacity of ML models perpetuates systemic biases and discrimination reflected in training data. The naive way to determine whether a model is biased is to compare its predictions on subpopulations of the test data. Imagine implementing this process on an expensive multi-layer feed-forward neural network -- only to find that the model is biased and should not be used for the task. It is of interest to determine whether an ML model is fair even before deploying it in practical real-time applications.\"]}]}],[\"$\",\"div\",null,{\"className\":\"$undefined\",\"children\":[\"$\",\"p\",null,{\"children\":[[\"$\",\"b\",null,{\"children\":\"RQ\"}],\": Can we measure the goodness of data for fairness of downstream ML tasks?\"]}]}]]}],[\"$\",\"div\",null,{\"className\":\"research_review__F1h4K\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"research_reviewTitle__Nvwft\",\"children\":\"Under Review\"}],[\"$\",\"h3\",null,{\"children\":\" The 'Who,' 'How,' and 'When,' of Elite Political Discourse on Twitter/X Before and After the Murder of George Floyd.\"}],[\"$\",\"div\",null,{\"className\":\"research_coauthors__PUOnm\",\"children\":\" Alyssa Smith, Ahana Bhattacharya, Holliday Sims, Kenneth Joseph\"}],[\"$\",\"div\",null,{\"className\":\"research_abstract__lZrrO\",\"children\":[\"$\",\"p\",null,{\"children\":[[\"$\",\"b\",null,{\"children\":\"Abstract\"}],\"$6\"]}]}],[\"$\",\"h3\",null,{\"children\":\" Justice in Child Welfare Policy: Towards the Development of a Contextual Ethics Framework for Deployment of AI in Human Service Systems.\"}],[\"$\",\"div\",null,{\"className\":\"research_coauthors__PUOnm\",\"children\":\"Maria Rodriguez, Seventy Hall, Kenneth Joseph, Ahana Bhattacharya, Benson Cai, Hannah Wilcox, and Connor Wurst\"}],[\"$\",\"div\",null,{\"className\":\"research_abstract__lZrrO\",\"children\":[\"$\",\"p\",null,{\"children\":[[\"$\",\"b\",null,{\"children\":\"Abstract\"}],\": Scholars investigating AI in high stakes settings have proposed ML solutions ranging from reformist to progressive, attempting to adjudicate between justice as equity and justice as fairness. Progressive work asks the system to reorder its prioritization of the values that define justice (equity), while reformist work builds tools that work within the existing justice value structure (fairness). The present work asks: what are the justice values (implied or enacted) by state-level child welfare administrative policy in the United States? We conduct a mixed-methods analysis of child welfare policy in the United States and find a range of implied justice values within administrative rules, from established concepts like fairness and equity to more nuanced foci on bodies as property. Our work contributes to a deeper understanding of the interplay between AI and policy, highlighting the importance of enacted values in shaping how we design AI tools in high stakes decision settings.\"]}]}]]}]]}]]}]}]],null],null]},[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"research\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/99898c7091afeebc.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]]}],null]},[[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"__className_2c91d1\",\"children\":[[\"$\",\"$L9\",null,{}],[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"styles\":null}],[\"$\",\"footer\",null,{\"className\":\"footer_footer__KDdEv\",\"children\":[\"$\",\"div\",null,{\"className\":\"footer_footerBlock__PXFG6\",\"children\":[[\"$\",\"div\",null,{\"className\":\"footer_socials__4wRIl\",\"children\":[[\"$\",\"a\",null,{\"href\":\"mailto:ahanabhattchrya@gmail.com\",\"children\":[\"$\",\"svg\",null,{\"className\":\"footer_gmail__f_p2B\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"viewBox\":\"0 0 512 512\",\"children\":[\"$\",\"path\",null,{\"d\":\"M64 112c-8.8 0-16 7.2-16 16l0 22.1L220.5 291.7c20.7 17 50.4 17 71.1 0L464 150.1l0-22.1c0-8.8-7.2-16-16-16L64 112zM48 212.2L48 384c0 8.8 7.2 16 16 16l384 0c8.8 0 16-7.2 16-16l0-171.8L322 328.8c-38.4 31.5-93.7 31.5-132 0L48 212.2zM0 128C0 92.7 28.7 64 64 64l384 0c35.3 0 64 28.7 64 64l0 256c0 35.3-28.7 64-64 64L64 448c-35.3 0-64-28.7-64-64L0 128z\"}]}]}],[\"$\",\"a\",null,{\"href\":\"https://www.linkedin.com/in/ah4na/\",\"children\":[\"$\",\"svg\",null,{\"className\":\"footer_linkedin__U8WKc\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"viewBox\":\"0 0 448 512\",\"children\":[\"$\",\"path\",null,{\"d\":\"M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z\"}]}]}]]}],[\"$\",\"div\",null,{\"className\":\"footer_footerText__hMIQC\",\"children\":[\"$\",\"p\",null,{\"children\":\"© Copyright 2024 Ahana Bhattacharya\"}]}]]}]}]]}]}],null],null],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$La\"],\"globalErrorComponent\":\"$b\",\"missingSlots\":\"$Wc\"}]]\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"Ahana Bhattacharya\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Generated by create next app\"}],[\"$\",\"link\",\"4\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"32x32\"}],[\"$\",\"meta\",\"5\",{\"name\":\"next-size-adjust\"}]]\n5:null\n"])</script></body></html>